# quantitative_analysis_plots.py – Unified plotting & analysis utilities
# -------------------------------------------------------------
# Author: ChatGPT (o3) – 2025‑08‑04
#
# This module merges the functionality that was previously spread
# across four stand‑alone scripts into a single importable file.
# It can be executed as a script *or* imported from a Jupyter
# notebook, giving you one canonical source of truth.
#
# Key improvements
# ----------------
# • **Single source CSV** – assumes *records_overlay_stats_all_classes.csv*
#   that contains every dental class with a `cls_id` column.
# • **Combined‑class outputs** – every plot now has an “All Classes”
#   view so you can inspect trends independent of pathology type.
# • **Notebook‑friendly** – all top‑level functions return `matplotlib`
#   Figure objects and accept an `ax` argument for easy subplotting.
# • **Filesystem hygiene** – autogenerated PNGs are written under
#   *plots/* by default; directories are created on‑the‑fly.
#
# Usage examples (in a notebook):
# >>> import quantitative_analysis_plots as xai
# >>> stats = xai.load_stats("records_overlay_stats_all_classes.csv")
# >>> ratios = xai.load_ratios("combined_embeddings_with_ratios_norm.csv")
# >>> fig = xai.plot_threshold_coverage(stats, thr=0.5)
# >>> fig
# -------------------------------------------------------------

from __future__ import annotations

import os
from pathlib import Path
from typing import Dict, List, Tuple

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.axes import Axes
from scipy.stats import gaussian_kde
import matplotlib.patches as mpatches

# ────────────────────────────────
#  —— Configuration ——
# ────────────────────────────────
CLASS_NAMES: Dict[int, str] = {
    0: "Cavity",
    1: "Implant",
    2: "Fillings",
    3: "Impacted Tooth",
}
CLASS_COLOURS: Dict[int, str] = {
    0: "tab:blue",
    1: "tab:orange",
    2: "tab:green",
    3: "tab:red",
}

# Coverage column names per method → pretty‑print label
METHODS: Dict[str, str] = {
    "occ_cv": "Occlusion Coverage",
    "lime_cv": "LIME Coverage",
    "rise_cv": "RISE Coverage",
}

# Confidence binning used for the threshold‑coverage plots
CONF_BINS = np.arange(0.0, 1.1, 0.1)  # [0, 1] inclusive, step 0.1

# Folder where PNGs will be written if the caller supplies no path
DEFAULT_PLOT_DIR = Path("plots")

# ────────────────────────────────
#  —— Loading helpers ——
# ────────────────────────────────

def _normalise_filename(raw: str) -> str:
    """Ensure .jpg extension and canonicalise YOLO's renamed images."""
    fixed = raw.replace("_rf_", ".rf.")
    return fixed if fixed.endswith(".jpg") else f"{fixed}.jpg"


def load_stats(csv_path: str | os.PathLike) -> pd.DataFrame:
    """Read the combined overlay-stats CSV and add helper columns."""
    df = pd.read_csv(csv_path)

    # ── ensure we have a numeric cls_id ─────────────────────────────
    if "cls_id" not in df.columns:
        if "class_id" in df.columns:          # common YOLO export
            df["cls_id"] = df["class_id"]
        elif "class" in df.columns:           # your case: string labels
            rev = {v: k for k, v in CLASS_NAMES.items()}
            df["cls_id"] = df["class"].map(rev)
        else:
            raise KeyError(
                "CSV must contain 'cls_id', 'class_id', or 'class' column."
            )
    # ───────────────────────────────────────────────────────────────

    if "conf_bin" not in df.columns:
        df["conf_bin"] = pd.cut(df["conf"], bins=CONF_BINS, include_lowest=False)

    if "Image Name" not in df.columns:
        df["Image Name"] = df["img"].astype(str).apply(_normalise_filename)

    return df



def load_ratios(csv_path: str | os.PathLike) -> pd.DataFrame:
    """Read the per‑image darkness / missing‑teeth ratios file."""
    df = pd.read_csv(csv_path)
    if "Image Name" not in df.columns:
        raise ValueError("Ratios CSV must contain an 'Image Name' column.")
    return df

# ────────────────────────────────
#  —— Plotting utilities ——
# ────────────────────────────────



def plot_threshold_coverage(
    df: pd.DataFrame,
    thr: float = 0.5,
    methods: list[str] | None = None,
    classes: dict[int,str] | None = None,
    cls_col: str = "cls_id",
    conf_col: str = "conf",
    n_bins: int = 10,
    out_file: str | Path | None = None,
) -> plt.Figure:
    """
    Plot coverage ≥ thr vs. confidence using n_bins regular bins in [0,1].
    """
    methods = methods or list(METHODS.keys())
    classes = classes or CLASS_NAMES

    # compute fixed-width bin edges and midpoints
    edges = np.linspace(0.0, 1.0, n_bins + 1)
    mids  = (edges[:-1] + edges[1:]) / 2.0

    # assign each sample to a bin index 0..n_bins-1
    df["reg_bin"] = pd.cut(df[conf_col], bins=edges, include_lowest=True, labels=False)

    fig, axes = plt.subplots(1, len(methods), figsize=(5 * len(methods), 4), sharey=True)
    if len(methods) == 1:
        axes = [axes]

    # precompute overall (all classes) coverage per bin
    overall = {}
    for m in methods:
        overall[m] = (
            df.groupby("reg_bin")[m]
              .apply(lambda x: (x >= thr).mean())
              .reindex(range(n_bins), fill_value=0.0)    # <-- now zeros
              .values
        )

    for ax, m in zip(axes, methods):
        # per-class
        for cls_id, cls_name in classes.items():
            rates = (
                df[df[cls_col] == cls_id]
                  .groupby("reg_bin")[m]
                  .apply(lambda x: (x >= thr).mean())
                  .reindex(range(n_bins), fill_value=0.0)  # <-- now zeros
                  .values
            )
            ax.plot(mids, rates, marker="o", alpha=0.6, label=cls_name)

        # all classes
        ax.plot(mids, overall[m],
                linestyle="--", linewidth=2, color="k", label="All Classes")

        ax.set_title(METHODS[m])
        ax.set_xlabel("Confidence")
        ax.set_xticks(mids)
        ax.set_xticklabels([f"{x:.2f}" for x in mids], rotation=45)
        ax.grid(True, linestyle="--", alpha=0.3)

    axes[0].set_ylabel(f"Coverage ≥ {thr}")
    # fig.suptitle(f"Coverage ≥ {thr} with {n_bins} Bins", y=1.02, fontsize=14)
    fig.suptitle(f"Coverage ≥ {thr} with {n_bins} Bins", fontsize=14)

    # build a single, de-duplicated legend from the first axis:
    handles, labels = axes[0].get_legend_handles_labels()
    # keep order but drop duplicates
    unique = dict(zip(labels, handles))
    fig.legend(
        unique.values(),
        unique.keys(),
        ncol=len(unique),
        bbox_to_anchor=(0.5, -0.05),
        loc="upper center",
        frameon=False
    )
    fig.tight_layout()

    if out_file:
        Path(out_file).parent.mkdir(parents=True, exist_ok=True)
        fig.savefig(out_file, dpi=300)

    return fig





def plot_coverage_scatter(
    df: pd.DataFrame,
    cls_id: int | str = "all",
    methods: List[str] | None = None,
    out_file: str | os.PathLike | None = None,
) -> plt.Figure:
    """Scatter coverage vs. confidence for a single class or all‑classes."""
    methods = methods or list(METHODS.keys())

    if cls_id == "all":
        sub = df.copy()
        title = "All Classes"
    else:
        sub = df[df["cls_id"] == cls_id].copy()
        title = CLASS_NAMES[int(cls_id)]

    case_colours = {"TP": "tab:blue", "FP": "tab:red",  "FN": "tab:green"}

    fig, axes = plt.subplots(1, len(methods), figsize=(5 * len(methods), 5), sharey=True)
    if len(methods) == 1:
        axes = [axes]

    for ax, m_key in zip(axes, methods):
        # map known cases, default to grey
        colors = sub["case"].map(case_colours).fillna("lightgrey")
        ax.scatter(
            sub["conf"],
            sub[m_key],
            c=colors,
            edgecolor="k",
            alpha=0.7,
            s=40,
        )
        if ax is axes[0]:
            handles = [
                ax.scatter([], [], color=c, edgecolor="k", s=60, label=case)
                for case, c in case_colours.items()
            ]
            ax.legend(handles=handles, title="Case", loc="upper left")
        ax.set_title(METHODS[m_key])
        ax.set_xlabel("YOLO Confidence")
        ax.grid(True, linestyle="--", alpha=0.4)

    axes[0].set_ylabel("Coverage")
    fig.suptitle(f"{title}: Coverage vs. Confidence", fontsize=14)
    fig.tight_layout(rect=[0, 0, 1, 0.94])

    if out_file is not None:
        out_file = Path(out_file)
        out_file.parent.mkdir(parents=True, exist_ok=True)
        fig.savefig(out_file, dpi=300)

    return fig


# —— Darkness × Missing‑teeth density plot ————————————————————

import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# your existing mapping from cls_id → friendly names
CLASS_NAMES = {
    0: "Cavity",
    1: "Implant",
    2: "Fillings",
    3: "Impacted Tooth",
}

def plot_darkness_missing_with_marginals(
    df_stats: pd.DataFrame,
    df_ratios: pd.DataFrame,
    cls_id: int | str = "all",
    out_file: str | Path | None = None,
    case_filter: list[str] = ["TP", "FP", 'FN'],
) -> None | plt.Figure:
    """
    If cls_id=='all', loop over ["all"] + each class_ID and save:
      - out_dir/dark_miss_all_jointmarg.png
      - out_dir/dark_miss_<class>_jointmarg.png  for each class
    Otherwise behave as before and return the single Figure.
    """
    # Determine output directory if provided
    out_dir = Path(out_file).parent if out_file else None

    # If top‐level call, recurse for all + each class
    if cls_id == "all":
        if out_dir is None:
            raise ValueError("Must pass out_file when cls_id='all' to know where to save")
        # 1) All classes
        plot_darkness_missing_with_marginals(
            df_stats,
            df_ratios,
            cls_id="__single_all__",
            out_file=str(out_dir / "dark_miss_all_jointmarg.png")
        )
        # 2) One per class
        for cid, cname in CLASS_NAMES.items():
            safe = cname.replace(" ", "_").lower()
            plot_darkness_missing_with_marginals(
                df_stats,
                df_ratios,
                cls_id=cid,
                out_file=str(out_dir / f"dark_miss_{safe}_jointmarg.png")
            )
        return  # nothing to return at top‐level

    # === Single‐plot logic ===
    # Map our sentinel "__single_all__" back to real "all"
    single_all = False
    if cls_id == "__single_all__":
        sub = df_stats.copy()
        title = "All Classes"
        single_all = True
    else:
        sub = df_stats[df_stats["cls_id"] == cls_id].copy()
        title = CLASS_NAMES[int(cls_id)]

    # Merge and sanity‐check
    merged = sub.merge(df_ratios, on="Image Name", how="inner")

    merged = df_stats[df_stats["case"].isin(case_filter)].merge(
        df_ratios, on="Image Name", how="inner"
    )
    if merged.empty:
        raise ValueError(f"No data to plot for '{title}'")

    # Build and draw JointGrid
    g = sns.JointGrid(
        data=merged,
        x="Darkness Ratio (Norm)",
        y="Missing Teeth Ratio (Norm)",
        height=6,
        space=0.1,
    )
    g.plot_joint(sns.scatterplot, color="k", alpha=0.5, s=30)
    g.plot_joint(
        sns.kdeplot,
        levels=5,
        color="C0",
        alpha=0.4,
        fill=True,
        linewidths=1
    )
    g.plot_marginals(sns.kdeplot, fill=True, color="C0", alpha=0.6)

    # Style
    g.set_axis_labels("Darkness Ratio (Norm)", "Missing Teeth Ratio (Norm)")
    g.ax_joint.grid(True, linestyle="--", alpha=0.3)
    g.ax_marg_x.set_xlim(0, 1)
    g.ax_marg_y.set_ylim(0, 1)
    plt.suptitle(f"{title}: Darkness vs. Missing-Teeth w/ Marginals", y=1.02)
    plt.tight_layout()
    plt.show()
    # Save or return
    if out_file:
        Path(out_file).parent.mkdir(exist_ok=True, parents=True)
        g.fig.savefig(out_file, dpi=300)
        plt.close(g.fig)
        return None
    else:
        return g.fig


def plot_marginal_distributions_per_case(
    df_stats: pd.DataFrame,
    df_ratios: pd.DataFrame,
    case_types: list[str]      = ["TP", "FP"],
    out_dir: str | Path | None = None,
):
    """
    For each case in case_types *and* for the combined set, produce side-by-side
    KDEs of Darkness and Missing-Teeth by class. Saves each figure as
      marginals_<case>.png   (case in TP, FP, or 'all')
    into out_dir (must be provided).
    """
    if out_dir is None:
        raise ValueError("Please provide out_dir to save the plots.")
    out_dir = Path(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # We'll loop over each 'case' and the combined set
    all_cases = ["all"] + case_types

    for case in all_cases:
        if case == "all":
            df = df_stats[df_stats["case"].isin(case_types)]
            title_case = "All Cases"
            fname = "marginals_all.png"
        else:
            df = df_stats[df_stats["case"] == case]
            title_case = f"Case = {case}"
            fname = f"marginals_{case.lower()}.png"

        # merge with ratios
        merged = df.merge(df_ratios, on="Image Name", how="inner")
        if merged.empty:
            print(f"[skip] no data for {title_case}")
            continue

        # map class names
        merged["class_name"] = merged["cls_id"].map(CLASS_NAMES)

        # make the figure
        fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=False)
        sns.kdeplot(
            data=merged,
            x="Darkness Ratio (Norm)",
            hue="class_name",
            common_norm=False,
            fill=True,
            ax=axes[0]
        )
        axes[0].set_title(f"{title_case}: Darkness by Class")
        axes[0].set_xlim(0, 1)
        axes[0].grid(True, linestyle="--", alpha=0.3)

        sns.kdeplot(
            data=merged,
            x="Missing Teeth Ratio (Norm)",
            hue="class_name",
            common_norm=False,
            fill=True,
            ax=axes[1]
        )
        axes[1].set_title(f"{title_case}: Missing-Teeth by Class")
        axes[1].set_xlim(0, 1)
        axes[1].grid(True, linestyle="--", alpha=0.3)

        fig.tight_layout()
        fig.show()
        save_path = out_dir / fname
        fig.savefig(save_path, dpi=300)
        plt.close(fig)
        print(f"Saved {title_case} marginal plot to {save_path}")


from scipy.stats import kruskal

from scipy.stats import kruskal

def kruskal_summary_single(
    df: pd.DataFrame,
    alpha: float = 0.05,
):
    """
    Internal helper: df must already be filtered & merged, and have 'class_name'.
    Returns (h_dark, p_dark), (h_miss, p_miss) and prints a short summary.
    """
    # Group by class_name
    dark_groups = [grp["Darkness Ratio (Norm)"].values
                   for _, grp in df.groupby("class_name")]
    miss_groups = [grp["Missing Teeth Ratio (Norm)"].values
                   for _, grp in df.groupby("class_name")]

    # Run tests
    h_dark, p_dark = kruskal(*dark_groups)
    h_miss, p_miss = kruskal(*miss_groups)

    # Print results
    print(f"   Darkness:       H = {h_dark:.2f}, p = {p_dark:.3f} "
          + ("(significant)" if p_dark < alpha else "(ns)"))
    print(f"   Missing-Teeth:  H = {h_miss:.2f}, p = {p_miss:.3f} "
          + ("(significant)" if p_miss < alpha else "(ns)"))
    print()
    return (h_dark, p_dark), (h_miss, p_miss)


def kruskal_summary_per_case(
    df_stats: pd.DataFrame,
    df_ratios: pd.DataFrame,
    case_types: list[str] = ["TP", "FP"],
    alpha: float = 0.05,
):
    """
    Run Kruskal–Wallis (Darkness & Missing) for:
      - Combined set of case_types (i.e. all but FN)
      - Each individual case in case_types

    Prints a neat summary for each.
    """
    print("=== Kruskal–Wallis Across Classes ===\n")

    # 1) Combined
    comb = df_stats[df_stats["case"].isin(case_types)].merge(
        df_ratios, on="Image Name", how="inner"
    )
    comb["class_name"] = comb["cls_id"].map(CLASS_NAMES)
    print(f"-- Combined cases ({', '.join(case_types)}) --")
    kruskal_summary_single(comb, alpha=alpha)

    # 2) Per individual case
    for case in case_types:
        dfc = df_stats[df_stats["case"] == case].merge(
            df_ratios, on="Image Name", how="inner"
        )
        dfc["class_name"] = dfc["cls_id"].map(CLASS_NAMES)
        print(f"-- Case = {case} --")
        kruskal_summary_single(dfc, alpha=alpha)


# —— Correlation summary ————————————————————————————————

def correlation_summary(
    df_stats: pd.DataFrame,
    df_ratios: pd.DataFrame,
    methods: List[str] | None = None,
) -> pd.DataFrame:
    """Compute mean coverage and Pearson correlations.

    Returns a tidy DataFrame with columns:
        [scope, method, mean_cov, rho_conf, rho_dark, rho_miss, strength_conf, …]
    where *scope* is either a class name or "All".
    """
    methods = methods or list(METHODS.keys())

    def _strength(r: float) -> str:
        a = abs(r)
        if a >= 0.7:
            return "strong"
        if a >= 0.3:
            return "moderate"
        if a >= 0.1:
            return "weak"
        return "none"

    records: List[Dict[str, str | float]] = []

    for scope_id in list(CLASS_NAMES.keys()) + ["all"]:
        if scope_id == "all":
            sub_stats = df_stats.copy()
            scope_name = "All"
        else:
            sub_stats = df_stats[df_stats["cls_id"] == scope_id].copy()
            scope_name = CLASS_NAMES[scope_id]

        merged = sub_stats.merge(df_ratios, on="Image Name", how="inner")
        if merged.empty:
            continue

        for m_key in methods:
            mean_cov = merged[m_key].mean()
            rho_conf = merged["conf"].corr(merged[m_key])
            rho_dark = merged["Darkness Ratio (Norm)"].corr(merged[m_key])
            rho_miss = merged["Missing Teeth Ratio (Norm)"].corr(merged[m_key])
            records.append(
                {
                    "scope": scope_name,
                    "method": METHODS[m_key],
                    "mean_cov": mean_cov,
                    "rho_conf": rho_conf,
                    "strength_conf": _strength(rho_conf),
                    "rho_dark": rho_dark,
                    "strength_dark": _strength(rho_dark),
                    "rho_miss": rho_miss,
                    "strength_miss": _strength(rho_miss),
                }
            )
    summary = pd.DataFrame.from_records(records)
    return summary

# ────────────────────────────────
#  —— Main (demo) entry‑point ——
# ────────────────────────────────

def _demo(csv_stats: str, csv_ratios: str, out_dir: str | os.PathLike = DEFAULT_PLOT_DIR):
    """Run every plot + correlation summary for quick inspection."""
    out_dir = Path(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    stats = load_stats(csv_stats)
    ratios = load_ratios(csv_ratios)

    # 1) Threshold‑coverage (thr ∊ {0, 0.5})
    for thr in (0.0, 0.5):
        fig = plot_threshold_coverage(
            stats,
            thr=thr,
            out_file=out_dir / f"coverage_vs_conf_thr{thr}.png",
        )
        plt.close(fig)

    # 2) Coverage‑scatter per class + combined
    for cid in list(CLASS_NAMES.keys()) + ["all"]:
        tag = "all" if cid == "all" else CLASS_NAMES[cid]
        fig = plot_coverage_scatter(
            stats,
            cls_id=cid,
            out_file=out_dir / f"scatter_{tag}.png",
        )
        plt.close(fig)

    # 3) Darkness‑vs‑missing density
    plot_darkness_missing_with_marginals(
        stats,
        ratios,
        cls_id="all",
            out_file=out_dir/"dark_miss_all_jointmarg.png"
)

    # 4) Correlation table (CSV + print)
    summary = correlation_summary(stats, ratios)
    summary.to_csv(out_dir / "correlation_summary.csv", index=False)
    print(summary)



def make_mask_filename(base: str, prefix: str, idx: int) -> str:
    """
    Construct the mask filename saved under each method directory.
    E.g. "{base}_{idx:03d}_{prefix}_mask.png"
    """
    return f"{base}_{idx:03d}_{prefix}_mask.png"

def show_low_coverage_examples(
        csv_stats: str,
        overlay_root: str,
        conf_range: tuple[float, float],
        cov_range: tuple[float, float],
        class_filter: list[str] | None,
        case_filter: list[str] | None,
        max_samples: int,
        methods: dict[str, tuple[str, str]] = None
    ) -> None:
    """
    Scan the stats CSV, apply optional class and case filters,
    then for specified cases and each method, display up to max_samples
    images where confidence and coverage are within given ranges.

    Args:
        csv_stats: Path to the CSV file with columns ['img','class','case','conf',...]
        overlay_root: Root directory where masks are stored in subfolders by class, case, method.
        conf_range: (min_conf, max_conf) inclusive.
        cov_range: (min_cov, max_cov) inclusive.
        class_filter: Optional list of class names to include.
        case_filter: Optional list of case labels ['TP','FP','FN'] to include.
        max_samples: Max number of images to show per method/case.
        methods: Dict mapping method names to (coverage_column, filename_prefix).
                 Defaults to DEFAULT_METHODS.
    """
    # Use default methods if none provided
    DEFAULT_METHODS  = {
    'Occlusion': ('occ_cv',  'occlusion'),
    'LIME':      ('lime_cv',  'lime'),
    'RISE':      ('rise_cv',  'rise'),}

    DEFAULT_CASES = ['TP']
 
    methods = methods or DEFAULT_METHODS

    # Debug: ensure methods mapping is correct
    # print("Using methods mapping:")
    # for k,v in methods.items(): print(f"  {k} -> {v}")

    df = pd.read_csv(csv_stats)
    df['base'] = df['img'].apply(lambda s: os.path.splitext(s)[0])

    # filter by class names if provided
    if class_filter:
        df = df[df['class'].isin(class_filter)]
        print(f"Filtering to classes: {class_filter}")

    # select which cases to iterate
    cases_to_show = case_filter if case_filter else DEFAULT_CASES
    print(f"Showing cases: {cases_to_show}")

    conf_min, conf_max = conf_range
    cov_min, cov_max   = cov_range

    for case in cases_to_show:
        df_case = df[df['case'] == case]
        print(f"\n=== Case: {case} (total rows: {len(df_case)}) ===")
        for method, (col, prefix, *_) in methods.items():
            # ensure the column exists
            if col not in df_case.columns:
                raise KeyError(f"Coverage column '{col}' not found in CSV.")
            
            # derive the hv‐column name (try '_hv', then '_hf')
            hv_col = col.replace("_cv", "_hv")
            if hv_col not in df_case.columns:
                hv_col = col.replace("_cv", "_hf")
            if hv_col not in df_case.columns:
                raise KeyError(f"Neither '{col.replace('_cv','_hv')}' nor "
                               f"'{col.replace('_cv','_hf')}' found in CSV.")


            sel = df_case[
                (df_case['conf'] >= conf_min) & (df_case['conf'] <= conf_max) &
                (df_case[col]    >= cov_min)  & (df_case[col]    <= cov_max)
            ]
            print(
                f"{method:<10} → {len(sel)} where "
                f"conf∈[{conf_min:.2f},{conf_max:.2f}], "
                f"cov∈[{cov_min:.2f},{cov_max:.2f}]"
            )

            count = 0
            for _, row in sel.iterrows():
                if count >= max_samples:
                    break
                mask_dir = os.path.join(overlay_root, row['class'], case, method)
                fname    = make_mask_filename(row['base'], prefix, int(row['idx']))
                fullpath = os.path.join(mask_dir, fname)

                img = cv2.imread(fullpath)
                plt.figure(figsize=(6,6))
                if img is None:
                    plt.text(0.5, 0.5, f"Missing {fname}", ha='center', va='center')
                    plt.axis('off')
                else:
                    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                    plt.axis('off')

                hv_val = row[hv_col]

                plt.title(
                    f"{method} | class={row['class']} | case={case}  "
                    f"| conf={row['conf']:.2f} | cov={row[col]:.2f} | hv={hv_val:.2f}"
                )
                plt.tight_layout()
                plt.show()
                count += 1
                


# def plot_cv_vs_hv(
#     df: pd.DataFrame,
#     cls_id: int | str = "all",
#     methods: List[str] | None = None,
#     out_file: str | os.PathLike | None = None,
# ) -> plt.Figure:
#     """
#     Scatter coverage (cv) vs. hv for a single class or all-classes.

#     Parameters
#     ----------
#     df
#         DataFrame containing columns like 'occ_cv', 'occ_hv', etc., plus 'cls_id' and 'case'.
#     cls_id
#         Integer class index or "all" to include all classes.
#     methods
#         List of cv‐column keys to plot (e.g. ['occ_cv','lime_cv']). Defaults to all keys in your METHODS dict.
#     out_file
#         If given, path where to save the figure (png, dpi=300).

#     Returns
#     -------
#     fig
#         Matplotlib Figure object.
#     """
#     methods = methods or list(METHODS.keys())

#     # filter by class if requested
#     if cls_id == "all":
#         sub = df.copy()
#         title = "All Classes"
#     else:
#         sub = df[df["cls_id"] == cls_id].copy()
#         title = CLASS_NAMES[int(cls_id)]

#     # map cases to colours
#     case_colours = {"TP": "tab:blue", "FP": "tab:red", "FN": "tab:green"}

#     # set up one axis per method
#     fig, axes = plt.subplots(1, len(methods),
#                              figsize=(5 * len(methods), 5),
#                              sharey=True)
#     if len(methods) == 1:
#         axes = [axes]

#     for ax, m_key in zip(axes, methods):
#         # map the cv → hv/hf column name
#         hv_key = m_key.replace("_cv", "_hv")
#         if hv_key not in sub.columns:
#             hv_key = m_key.replace("_cv", "_hf")
#         if hv_key not in sub.columns:
#             raise KeyError(
#                 f"Expected column '{m_key.replace('_cv','_hv')}' or "
#                 f"'{m_key.replace('_cv','_hf')}' in DataFrame"
#             )

#         # colour each point by TP/FP/FN
#         colours = sub["case"].map(case_colours).fillna("lightgrey")
#         ax.scatter(
#             sub[m_key],            # coverage
#             sub[hv_key],           # hausdorff ("hf")
#             c=colours,
#             edgecolor="k",
#             alpha=0.7,
#             s=40,
#         )
#         # only draw the legend on the first subplot
#         if ax is axes[0]:
#             handles = [
#                 ax.scatter([], [], color=c, edgecolor="k", s=60, label=case)
#                 for case, c in case_colours.items()
#             ]
#             ax.legend(handles=handles, title="Case", loc="upper left")

#         ax.set_title(METHODS[m_key])
#         ax.set_xlabel("Coverage (cv)")
#         ax.set_ylabel("Hausdorff distance (hv)")
#         ax.grid(True, linestyle="--", alpha=0.4)

#     fig.suptitle(f"{title}: cv vs. hv", fontsize=14)
#     fig.tight_layout(rect=[0, 0, 1, 0.94])

#     if out_file:
#         out_path = Path(out_file)
#         out_path.parent.mkdir(parents=True, exist_ok=True)
#         fig.savefig(out_path, dpi=300)

#     return fig
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
from pathlib import Path

def plot_cv_vs_hv(
    df: pd.DataFrame,
    cls_id: int | str = "all",
    methods: List[str] | None = None,
    out_file: str | os.PathLike | None = None,
) -> plt.Figure:
    """
    Scatter coverage (cv) vs. hv for a single class or all-classes,
    with unified marginal histograms and no color distinctions.
    """
    methods = methods or list(METHODS.keys())

    # filter by class if requested
    if cls_id == "all":
        sub = df.copy()
        title = "All Classes"
    else:
        sub = df[df["cls_id"] == cls_id].copy()
        title = CLASS_NAMES[int(cls_id)]

    figs = []
    for m_key in methods:
        # pick hv/hf column
        hv_key = m_key.replace("_cv", "_hv")
        if hv_key not in sub.columns:
            hv_key = m_key.replace("_cv", "_hf")

        # set up 2×2 grid, drop top-right
        fig = plt.figure(figsize=(6,6))
        gs  = GridSpec(2,2, width_ratios=(4,1), height_ratios=(1,4),
                       hspace=0.05, wspace=0.05, figure=fig)
        ax_hist_x = fig.add_subplot(gs[0,0])
        ax_main   = fig.add_subplot(gs[1,0])
        ax_hist_y = fig.add_subplot(gs[1,1])

        # 1) Main scatter—single color
        ax_main.scatter(
            sub[m_key],
            sub[hv_key],
            color="k",
            alpha=0.7,
            s=30
        )
        ax_main.set_xlabel("Coverage (cv)")
        ax_main.set_ylabel("Hausdorff/HF")
        ax_main.grid(True, linestyle="--", alpha=0.4)

        # 2) Marginal histograms—single color
        bins = 20
        ax_hist_x.hist(sub[m_key], bins=bins, density=True,
                       color="grey", alpha=0.5)
        ax_hist_y.hist(sub[hv_key], bins=bins, density=True,
                       orientation="horizontal", color="grey", alpha=0.5)

        # clean up marginals
        ax_hist_x.set_xticks([])
        ax_hist_x.set_yticks([])
        ax_hist_y.set_xticks([])
        ax_hist_y.set_yticks([])

        fig.suptitle(f"{title}: {METHODS[m_key]} cv vs. hv", fontsize=14)
        fig.tight_layout(rect=[0,0,1,0.95])

        if out_file:
            out_path = Path(out_file)
            # build "<stem>_<method>.png" under the same directory
            save_path = out_path.parent / f"{out_path.stem}_{m_key}{out_path.suffix}"
            save_path.parent.mkdir(parents=True, exist_ok=True)
            fig.savefig(save_path, dpi=300)
        figs.append(fig)

    return figs[0] if len(figs)==1 else figs


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Generate XAI coverage plots & correlation summaries from a single CSV",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument("--stats", default="records_overlay_stats_all_classes.csv", help="Overlay stats CSV")
    parser.add_argument("--ratios", default="combined_embeddings_with_ratios_norm.csv", help="Ratios CSV")
    parser.add_argument("--out", default=str(DEFAULT_PLOT_DIR), help="Output directory for PNGs & CSV")
    args = parser.parse_args()

    # Matplotlib safety on shared file‑systems
    os.environ.setdefault("MPLCONFIGDIR", "/tmp")

    _demo(args.stats, args.ratios, args.out)
